{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mariemtouihri/GRAM-Metric/blob/main/Average_Neighbor_Degree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6TSpYJDjiif"
      },
      "source": [
        "# 1 - Import libraries and data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BS1aXzRKnkEa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import networkx as nx\n",
        "from scipy.stats import spearmanr, kendalltau\n",
        "import matplotlib.pyplot as plt\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2JzNbyKrB1X"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4OppnluhXs4"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "  Load all matrices from my drive in a dictionary (There are 8 Groups of matrices,\n",
        "   each time we will work with a specific group in all cells and then repeat all\n",
        "    of it to the next group)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Read the adjacency matrix\n",
        "loaded_data_dict = {}\n",
        "noises = [i for i in range(0,110,10)]\n",
        "j = 1 # To select G1 and so on (it will be applied on all other cells)\n",
        "\n",
        "for noise in noises:\n",
        "  file_path = f'/content/drive/MyDrive/Colab_Notebooks/Copie de matrices_noise_G{j}_{noise}%.npy'\n",
        "  loaded_data = np.load(file_path)\n",
        "  loaded_data_dict[noise] = loaded_data\n",
        "\n",
        "print(f\"Matrices G{j} are loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QiH5WKkvIsPN"
      },
      "outputs": [],
      "source": [
        "len(loaded_data_dict[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42MS93orZtcI"
      },
      "source": [
        "### To verify percentage of modification for the loaded matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82CytTFvZmBS"
      },
      "outputs": [],
      "source": [
        "# Calculate the percentage of modification\n",
        "def calculate_modification_percentage(original_matrix, modified_matrix):\n",
        "    total_elements = original_matrix.size\n",
        "    modified_elements = np.count_nonzero(original_matrix != modified_matrix)\n",
        "    modification_percentage = (modified_elements / (total_elements-original_matrix.shape[0])) * 100\n",
        "    return modification_percentage\n",
        "\n",
        "original_matrix = loaded_data_dict[0][200]  #insert a specific  matrix here\n",
        "modified_matrix = loaded_data_dict[30][200]  # You must get 30% noise result\n",
        "\n",
        "# Calculate and print the modification percentage\n",
        "percentage = calculate_modification_percentage(original_matrix, modified_matrix)\n",
        "print(f\"Percentage of modification: {percentage:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcNMDDiXaTD-"
      },
      "source": [
        "### Define needed functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_SxVyOgR0f5"
      },
      "outputs": [],
      "source": [
        "def avg_n_d (matrices):\n",
        "\n",
        "    avg_n_values = []\n",
        "    for i in range(len(matrices)):\n",
        "      matrix = matrices[i]\n",
        "      G = nx.DiGraph(matrix)\n",
        "      avg_n_v = nx.average_neighbor_degree(G, weight='weight', source= 'in+out')\n",
        "\n",
        "\n",
        "      avg_n_list = list(avg_n_v.values())\n",
        "      avg_n_values.extend(avg_n_list)\n",
        "\n",
        "    return avg_n_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiTYj04ebbPk"
      },
      "outputs": [],
      "source": [
        "# This metric works on node level ! (it is different from metrics that work on graph level)\n",
        "def calculate_correlations(original_values, modified_values, j, x):\n",
        "\n",
        "  # # Add noise to avoid getting nan as correlation values\n",
        "  # noise = np.random.uniform(0, 1e-6, len(original_values))\n",
        "  # original_values += noise\n",
        "  # noise = np.random.uniform(0, 1e-6, len(modified_values))\n",
        "  # modified_values += noise\n",
        "\n",
        "  p = []\n",
        "  sp = []\n",
        "  ktau = []\n",
        "  corr_dict = {}\n",
        "  for i in range(0, len(original_values), 90):\n",
        "    # Calculate Pearson Correlation\n",
        "    p_correlation = np.corrcoef(original_values[i:i+90], modified_values[i:i+90])[0, 1]\n",
        "    p.append(p_correlation)\n",
        "\n",
        "    # Calculate Spearman correlation\n",
        "    sp_correlation, _ = spearmanr(original_values[i:i+90], modified_values[i:i+90])\n",
        "    sp.append(sp_correlation)\n",
        "\n",
        "    # Calculate Kendall Tau correlation\n",
        "    ktau_correlation, p_value = kendalltau(original_values[i:i+90], modified_values[i:i+90])\n",
        "    ktau.append(ktau_correlation)\n",
        "\n",
        "\n",
        "  # Store correlation results to a json file for each matrix\n",
        "  corr_dict['pearson_values'] = p\n",
        "  corr_dict['spearman_values'] = sp\n",
        "  corr_dict['ktau_values'] = ktau\n",
        "\n",
        "\n",
        "  # Define the file path for the new JSON file\n",
        "  file_path = f'/content/drive/MyDrive/Colab_Notebooks/avg_n_d/avg_n_d_all_correlations_matrices_G{j}_{x}%.json'\n",
        "\n",
        "  # Serialize and save the dictionary to the new file\n",
        "  with open(file_path, 'w') as json_file:\n",
        "      json.dump(corr_dict, json_file)\n",
        "\n",
        "  print(f\"Results saved to {file_path}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # Calculate avg of correlations of all matrices\n",
        "  pearson_value = np.mean(p, axis=0)\n",
        "  spearman_value = np.mean(sp, axis=0)\n",
        "  ktau_value = np.mean(ktau, axis=0)\n",
        "\n",
        "  return pearson_value, spearman_value, ktau_value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4MZeWh_pzDU"
      },
      "source": [
        "### Start calculations and save them to files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPsqqSO4YKi5"
      },
      "outputs": [],
      "source": [
        "loaded_data_dict = {}\n",
        "noises = [i for i in range(0,110,10)]\n",
        "\n",
        "# To select G1 and so on (it will be applied on all other cells)\n",
        "\n",
        "for j in range(1,9,1):\n",
        "\n",
        "  for noise in noises:\n",
        "    file_path = f'/content/drive/MyDrive/Colab_Notebooks/Copie de matrices_noise_G{j}_{noise}%.npy'\n",
        "    loaded_data = np.load(file_path)\n",
        "    loaded_data_dict[noise] = loaded_data\n",
        "\n",
        "  print(f\"Matrices G{j} are loaded successfully!\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  avg_n_d_dict = {} # to store results in a dictionary\n",
        "\n",
        "  for percent, loaded_data in loaded_data_dict.items():\n",
        "      avg_n_d_dict[percent] = avg_n_d(loaded_data)\n",
        "\n",
        "\n",
        "  # store results in an .npy file\n",
        "\n",
        "  dict_values = list(avg_n_d_dict.values())\n",
        "  dict_array = np.array(dict_values)\n",
        "\n",
        "  file_path = f'/content/drive/MyDrive/Colab_Notebooks/avg_n_d/avg_n_d_values_matrices_G{j}.npy'\n",
        "\n",
        "  np.save(file_path, dict_array)\n",
        "  print(f\"Values G{j} are saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qG55pFt6Iw5"
      },
      "outputs": [],
      "source": [
        "# To select 25 out of 100 for each matrix\n",
        "my_list = [i for i in range(99000)]\n",
        "l=[]\n",
        "for i in range(0,90001,9000):\n",
        "  l.extend(my_list[i:i+2250])\n",
        "\n",
        "\n",
        "for j in range(1,9,1):\n",
        "\n",
        "  file_path = f'/content/drive/MyDrive/Colab_Notebooks/avg_n_d/avg_n_d_values_matrices_G{j}.npy'\n",
        "  data = np.load(file_path)\n",
        "  noises = [ i for i in range(0,110,10)]\n",
        "  closeness_dict= {}\n",
        "  i=0\n",
        "  for noise in noises:\n",
        "\n",
        "      closeness_dict[noise] = data[i]\n",
        "      i+=1\n",
        "\n",
        "  # We have 90 value for 90 node\n",
        "  new = {}\n",
        "  for noise in noises:\n",
        "    new[noise] = []\n",
        "    for i in range(len(l)):\n",
        "      new[noise].append(closeness_dict[noise][l[i]])\n",
        "\n",
        "  print(len(new[0]))\n",
        "\n",
        "\n",
        "\n",
        "  # store results in an .npy file\n",
        "\n",
        "  dict_values = list(new.values())\n",
        "  dict_array = np.array(dict_values)\n",
        "  file_path = f'/content/drive/MyDrive/Colab_Notebooks/avg_n_d/avg_n_d_values_matrices_25gen_G{j}.npy'\n",
        "\n",
        "  np.save(file_path, dict_array)\n",
        "  print(f\"Values 25gen G{j} are saved\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_UxjJ6KkkCc"
      },
      "outputs": [],
      "source": [
        "j=1\n",
        "file_path = f'/content/drive/MyDrive/Colab_Notebooks/avg_n_d/avg_n_d_values_matrices_25gen_G{j}.npy'\n",
        "data = np.load(file_path)\n",
        "noises = [ i for i in range(0,110,10)]\n",
        "avg_n_d_dict= {}\n",
        "i=0\n",
        "for noise in noises:\n",
        "  avg_n_d_dict[noise] = data[i]\n",
        "  i+=1\n",
        "\n",
        "print(len(avg_n_d_dict))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noises = [ i for i in range(0,110,10)]\n",
        "\n",
        "for j in  range(1,2,1):\n",
        "  file_path = f'/content/drive/MyDrive/Colab_Notebooks/avg_n_d/avg_n_d_values_matrices_G{j}.npy'\n",
        "  data = np.load(file_path)\n",
        "  hub_auth_dict= {}\n",
        "  i=0\n",
        "  for noise in noises:\n",
        "      hub_auth_dict[noise] = data[i]\n",
        "      i+=1\n",
        "\n",
        "  print(len(hub_auth_dict[10]))"
      ],
      "metadata": {
        "id": "2fpGqB7iUU9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noises = [ i for i in range(0,110,10)]\n",
        "\n",
        "for j in  range(4,9,1):\n",
        "  file_path = f'/content/drive/MyDrive/Colab_Notebooks/avg_n_d/avg_n_d_values_matrices_G{j}.npy'\n",
        "  data = np.load(file_path)\n",
        "  hub_auth_dict= {}\n",
        "  i=0\n",
        "  for noise in noises:\n",
        "      hub_auth_dict[noise] = data[i]\n",
        "      i+=1\n",
        "\n",
        "  print(len(hub_auth_dict))\n",
        "\n",
        "\n",
        "  pearson_values = [1]\n",
        "  spearman_values = [1]\n",
        "  ktau_values = [1]\n",
        "\n",
        "  for i in range(10,110,10):\n",
        "    pearson_value, spearman_value, ktau_value = calculate_correlations(hub_auth_dict[0], hub_auth_dict[i], j, i)\n",
        "    pearson_values.append(pearson_value)\n",
        "    spearman_values.append(spearman_value)\n",
        "    ktau_values.append(ktau_value)\n",
        "\n",
        "\n",
        "\n",
        "  # Store correlation results to a json file for each G\n",
        "\n",
        "  corr_dict = {}\n",
        "  corr_dict['pearson_values'] = pearson_values\n",
        "  corr_dict['spearman_values'] = spearman_values\n",
        "  corr_dict['ktau_values'] = ktau_values\n",
        "\n",
        "\n",
        "  # Define the file path for the new JSON file\n",
        "  file_path = f'/content/drive/MyDrive/Colab_Notebooks/avg_n_d/avg_n_d_correlations_matrices_G{j}.json'\n",
        "\n",
        "  # Serialize and save the dictionary to the new file\n",
        "  with open(file_path, 'w') as json_file:\n",
        "      json.dump(corr_dict, json_file)\n",
        "\n",
        "  print(f\"Results saved to {file_path}\")\n"
      ],
      "metadata": {
        "id": "_BbK0FHZQf3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wClNXcjCvupj"
      },
      "outputs": [],
      "source": [
        "pearson_values = [1]\n",
        "spearman_values = [1]\n",
        "ktau_values = [1]\n",
        "\n",
        "for i in range(10,110,10):\n",
        "  pearson_value, spearman_value, ktau_value = calculate_correlations(avg_n_d_dict[0], avg_n_d_dict[i], i)\n",
        "  pearson_values.append(pearson_value)\n",
        "  spearman_values.append(spearman_value)\n",
        "  ktau_values.append(ktau_value)\n",
        "  print(f\"for {i}% noise (Pearson value: {pearson_value}), (Spearman value: {spearman_value}), (Kendall-tau value: {ktau_value})\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Store correlation results to a json file for each G\n",
        "\n",
        "corr_dict = {}\n",
        "corr_dict['pearson_values'] = pearson_values\n",
        "corr_dict['spearman_values'] = spearman_values\n",
        "corr_dict['ktau_values'] = ktau_values\n",
        "\n",
        "\n",
        "# Define the file path for the new JSON file\n",
        "file_path = f'/content/drive/MyDrive/Colab_Notebooks/avg_n_d/avg_n_d_correlations_matrices_G{j}.json'\n",
        "\n",
        "# Serialize and save the dictionary to the new file\n",
        "with open(file_path, 'w') as json_file:\n",
        "    json.dump(corr_dict, json_file)\n",
        "\n",
        "print(f\"Results saved to {file_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ji2Xqm8XPzRl"
      },
      "outputs": [],
      "source": [
        "# Store correlation results to a json file for each G\n",
        "\n",
        "corr_dict = {}\n",
        "corr_dict['pearson_values'] = pearson_values\n",
        "corr_dict['spearman_values'] = spearman_values\n",
        "corr_dict['ktau_values'] = ktau_values\n",
        "\n",
        "\n",
        "# Define the file path for the new JSON file\n",
        "file_path = f'/content/drive/MyDrive/Colab_Notebooks/avg_n_d/avg_n_d_correlations_matrices_G{j}.json'\n",
        "\n",
        "# Serialize and save the dictionary to the new file\n",
        "with open(file_path, 'w') as json_file:\n",
        "    json.dump(corr_dict, json_file)\n",
        "\n",
        "print(f\"Results saved to {file_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVW7xq50wpfe"
      },
      "outputs": [],
      "source": [
        "# Plot results\n",
        "modification_rates = [f\"{i}%\" for i in range(0,110,10)]\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "plt.plot(modification_rates, pearson_values, marker='o', label= \"Pearson\")\n",
        "plt.plot(modification_rates, spearman_values, marker='o', label= \"Spearman\")\n",
        "plt.plot(modification_rates, ktau_values, marker='o', label= \"Kendall Tau\")\n",
        "\n",
        "plt.xlabel(\"Modification Percentage\")\n",
        "plt.ylabel(\"Correlation\")\n",
        "plt.title(\"Correlation of Average Neighbor Degree (Original vs Modified)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8LPRfeNi4Ba"
      },
      "outputs": [],
      "source": [
        "# read correlations from stored files G1, G2, ..\n",
        "\n",
        "\n",
        "pearson_values = []\n",
        "spearman_values = []\n",
        "ktau_values = []\n",
        "\n",
        "\n",
        "for j in range(8):\n",
        "\n",
        "  # Define the path to your JSON file\n",
        "  file_path = f'/content/drive/MyDrive/Colab_Notebooks/avg_n_d/avg_n_d_correlations_matrices_G{j+1}.json'\n",
        "\n",
        "  # Open and read the JSON file\n",
        "  with open(file_path, 'r') as json_file:\n",
        "      corr_dict = json.load(json_file)\n",
        "\n",
        "      if j== 0:\n",
        "        pearson_values.extend(corr_dict[\"pearson_values\"])\n",
        "        spearman_values.extend(corr_dict[\"spearman_values\"])\n",
        "        ktau_values.extend(corr_dict[\"ktau_values\"])\n",
        "      else:\n",
        "        pearson_values = np.vstack((pearson_values, corr_dict[\"pearson_values\"]))\n",
        "        spearman_values = np.vstack((spearman_values, corr_dict[\"spearman_values\"]))\n",
        "        ktau_values = np.vstack((ktau_values, corr_dict[\"ktau_values\"]))\n",
        "\n",
        "\n",
        "# Ready to be plotted (results from all matrices horray!)\n",
        "pearson_values = np.mean(pearson_values, axis=0)\n",
        "spearman_values = np.mean(spearman_values, axis=0)\n",
        "ktau_values = np.mean(ktau_values, axis=0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Plot results\n",
        "modification_rates = [f\"{i}%\" for i in range(0,110,10)]\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "plt.plot(modification_rates, pearson_values, marker='o', label= \"Pearson\")\n",
        "plt.plot(modification_rates, spearman_values, marker='o', label= \"Spearman\")\n",
        "plt.plot(modification_rates, ktau_values, marker='o', label= \"Kendall Tau\")\n",
        "\n",
        "plt.xlabel(\"Modification Percentage\")\n",
        "plt.ylabel(\"Correlation\")\n",
        "plt.title(\"Correlation of Average Neighbor Degree (Original vs Modified)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4KW4K2slOdhO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}