{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Fge6SrdRwHGbNDKGbJK3c_saxK9geyqo",
      "authorship_tag": "ABX9TyN+Ns0i11WWkAJxDWTXZqQA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mariemtouihri/GRAM-Metric/blob/main/Eigenvector_centrality.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 - Import libraries and data"
      ],
      "metadata": {
        "id": "h6TSpYJDjiif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import networkx as nx\n",
        "from scipy.stats import spearmanr, kendalltau\n",
        "import matplotlib.pyplot as plt\n",
        "import community\n",
        "import json"
      ],
      "metadata": {
        "id": "BS1aXzRKnkEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "  Load all matrices from my drive in a dictionary (There are 8 Groups of matrices,\n",
        "   each time we will work with a specific group in all cells and then repeat all\n",
        "    of it to the next group)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Read the adjacency matrix\n",
        "loaded_data_dict = {}\n",
        "noises = [ i for i in range(0,110,10)]\n",
        "j=1 # To select G1 and so on\n",
        "for noise in noises:\n",
        "  file_path = f'/content/drive/MyDrive/Colab_Notebooks/Copy of Copie de matrices_noise_G{j}_{noise}%.npy'\n",
        "  loaded_data = np.load(file_path)\n",
        "  loaded_data_dict[noise] = loaded_data\n",
        "\n",
        "print(f\"Matrices G{j} are loaded successfully!\")"
      ],
      "metadata": {
        "id": "U4OppnluhXs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define needed functions"
      ],
      "metadata": {
        "id": "qaXdIQVnssvD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eigen (matrices):\n",
        "\n",
        "    eigen_c_values = []\n",
        "    for i in range(len(matrices)):\n",
        "      matrix = matrices[i]\n",
        "      G = nx.DiGraph(matrix)\n",
        "      eigenvector_c = nx.eigenvector_centrality(G, weight='weight', max_iter=500)\n",
        "\n",
        "      eigenvector_c_values = list(eigenvector_c.values())\n",
        "      eigen_c_values.extend(eigenvector_c_values)\n",
        "\n",
        "    return eigen_c_values"
      ],
      "metadata": {
        "id": "M9xpLqzmee6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This metric works on node level ! (it is different from metrics that work on graph level)\n",
        "def calculate_correlations(original_values, modified_values, j, x):\n",
        "  p = []\n",
        "  sp = []\n",
        "  ktau = []\n",
        "  corr_dict = {}\n",
        "  for i in range(0, len(original_values), 90):\n",
        "    # Calculate Pearson Correlation\n",
        "    p_correlation = np.corrcoef(original_values[i:i+90], modified_values[i:i+90])[0, 1]\n",
        "    p.append(p_correlation)\n",
        "\n",
        "    # Calculate Spearman correlation\n",
        "    sp_correlation, _ = spearmanr(original_values[i:i+90], modified_values[i:i+90])\n",
        "    sp.append(sp_correlation)\n",
        "\n",
        "    # Calculate Kendall Tau correlation\n",
        "    ktau_correlation, p_value = kendalltau(original_values[i:i+90], modified_values[i:i+90])\n",
        "    ktau.append(ktau_correlation)\n",
        "\n",
        "\n",
        "  # Store correlation results to a json file for each matrix\n",
        "  corr_dict['pearson_values'] = p\n",
        "  corr_dict['spearman_values'] = sp\n",
        "  corr_dict['ktau_values'] = ktau\n",
        "\n",
        "\n",
        "  # Define the file path for the new JSON file\n",
        "  file_path = f'/content/drive/MyDrive/Colab_Notebooks/eigen/eigen_all_correlations_matrices_G{j}_{x}%.json'\n",
        "\n",
        "  # Serialize and save the dictionary to the new file\n",
        "  with open(file_path, 'w') as json_file:\n",
        "      json.dump(corr_dict, json_file)\n",
        "\n",
        "  print(f\"Results saved to {file_path}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # Calculate avg of correlations of all matrices\n",
        "  pearson_value = np.mean(p, axis=0)\n",
        "  spearman_value = np.mean(sp, axis=0)\n",
        "  ktau_value = np.mean(ktau, axis=0)\n",
        "\n",
        "  return pearson_value, spearman_value, ktau_value"
      ],
      "metadata": {
        "id": "yiTYj04ebbPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Start calculations and save them to files\n"
      ],
      "metadata": {
        "id": "FSuvCzkCsmDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "j=1\n",
        "file_path = f'/content/drive/MyDrive/Colab_Notebooks/eigen/eigen_values_matrices_G{j}.npy'\n",
        "data = np.load(file_path)\n",
        "noises = [ i for i in range(0,110,10)]\n",
        "closeness_dict= {}\n",
        "i=0\n",
        "for noise in noises:\n",
        "\n",
        "    closeness_dict[noise] = data[i]\n",
        "    i+=1\n",
        "\n",
        "print(len(closeness_dict[0]))"
      ],
      "metadata": {
        "id": "QkJ4c-WSRkXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eigen_dict = {} # to store results in a dictionary\n",
        "\n",
        "for percent, loaded_data in loaded_data_dict.items():\n",
        "    eigen_dict[percent] = eigen(loaded_data)\n",
        "\n",
        "\n",
        "\n",
        "# store results in an .npy file\n",
        "\n",
        "dict_values = list(eigen_dict.values())\n",
        "dict_array = np.array(dict_values)\n",
        "\n",
        "file_path = f'/content/drive/MyDrive/Colab_Notebooks/eigen/eigen_values_matrices_G{j}.npy'\n",
        "\n",
        "np.save(file_path, dict_array)\n"
      ],
      "metadata": {
        "id": "hPsqqSO4YKi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "  Load all matrices from my drive in a dictionary (There are 8 Groups of matrices,\n",
        "   each time we will work with a specific group in all cells and then repeat all\n",
        "    of it to the next group)\n",
        "\n",
        "\"\"\"\n",
        "loaded_data_dict = {}\n",
        "noises = [i for i in range(0,110,10)]\n",
        "\n",
        "# To select G1 and so on ..\n",
        "for j in range(1,9,1):\n",
        "\n",
        "  for noise in noises:\n",
        "    file_path = f'/content/drive/MyDrive/Colab_Notebooks/Copy of Copie de matrices_noise_G{j}_{noise}%.npy'\n",
        "    loaded_data = np.load(file_path)\n",
        "    loaded_data_dict[noise] = loaded_data\n",
        "\n",
        "  print(f\"Matrices G{j} are loaded !\")\n",
        "\n",
        "\n",
        "\n",
        "  eigen_dict = {} # to store results in a dictionary\n",
        "\n",
        "  for percent, loaded_data in loaded_data_dict.items():\n",
        "      eigen_dict[percent] = eigen(loaded_data)\n",
        "\n",
        "\n",
        "\n",
        "  # store results in an .npy file\n",
        "\n",
        "  dict_values = list(eigen_dict.values())\n",
        "  dict_array = np.array(dict_values)\n",
        "\n",
        "  file_path = f'/content/drive/MyDrive/Colab_Notebooks/eigen/eigen_values_matrices_G{j}.npy'\n",
        "\n",
        "  np.save(file_path, dict_array)\n",
        "  print(f\"Values G{j} are saved\")"
      ],
      "metadata": {
        "id": "kJ2KUnTaZheQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noises = [ i for i in range(0,110,10)]\n",
        "\n",
        "for j in  range(1,9,1):\n",
        "  file_path = f'/content/drive/MyDrive/Colab_Notebooks/eigen/eigen_values_matrices_G{j}.npy'\n",
        "  data = np.load(file_path)\n",
        "  hub_auth_dict= {}\n",
        "  i=0\n",
        "  for noise in noises:\n",
        "      hub_auth_dict[noise] = data[i]\n",
        "      i+=1\n",
        "\n",
        "  print(len(hub_auth_dict))\n",
        "\n",
        "\n",
        "  pearson_values = [1]\n",
        "  spearman_values = [1]\n",
        "  ktau_values = [1]\n",
        "\n",
        "  for i in range(10,110,10):\n",
        "    pearson_value, spearman_value, ktau_value = calculate_correlations(hub_auth_dict[0], hub_auth_dict[i], j, i)\n",
        "    pearson_values.append(pearson_value)\n",
        "    spearman_values.append(spearman_value)\n",
        "    ktau_values.append(ktau_value)\n",
        "\n",
        "\n",
        "\n",
        "  # Store correlation results to a json file for each G\n",
        "\n",
        "  corr_dict = {}\n",
        "  corr_dict['pearson_values'] = pearson_values\n",
        "  corr_dict['spearman_values'] = spearman_values\n",
        "  corr_dict['ktau_values'] = ktau_values\n",
        "\n",
        "\n",
        "  # Define the file path for the new JSON file\n",
        "  file_path = f'/content/drive/MyDrive/Colab_Notebooks/eigen/eigen_correlations_matrices_G{j}.json'\n",
        "\n",
        "  # Serialize and save the dictionary to the new file\n",
        "  with open(file_path, 'w') as json_file:\n",
        "      json.dump(corr_dict, json_file)\n",
        "\n",
        "  print(f\"Results saved to {file_path}\")\n"
      ],
      "metadata": {
        "id": "dKRNEPcrLxFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pearson_values = [1]\n",
        "spearman_values = [1]\n",
        "ktau_values = [1]\n",
        "\n",
        "for i in range(10,110,10):\n",
        "  pearson_value, spearman_value, ktau_value = calculate_correlations(eigen_dict[0], eigen_dict[i])\n",
        "  pearson_values.append(pearson_value)\n",
        "  spearman_values.append(spearman_value)\n",
        "  ktau_values.append(ktau_value)\n"
      ],
      "metadata": {
        "id": "2yDgWbMltIRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store correlation results to a json file for each G\n",
        "\n",
        "\n",
        "corr_dict = {}\n",
        "corr_dict['pearson_values'] = pearson_values\n",
        "corr_dict['spearman_values'] = spearman_values\n",
        "corr_dict['ktau_values'] = ktau_values\n",
        "\n",
        "\n",
        "# Define the file path for the new JSON file\n",
        "file_path = f'/content/drive/MyDrive/Colab_Notebooks/eigen/eigen_correlations_matrices_G{j}.json'\n",
        "\n",
        "# Serialize and save the dictionary to the new file\n",
        "with open(file_path, 'w') as json_file:\n",
        "    json.dump(corr_dict, json_file)\n",
        "\n",
        "print(f\"Results saved to {file_path}\")\n"
      ],
      "metadata": {
        "id": "F55P-zV7PhLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot results\n",
        "modification_rates = [f\"{i}%\" for i in range(0,110,10)]\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "plt.plot(modification_rates, pearson_values, marker='o', label= \"Pearson\")\n",
        "plt.plot(modification_rates, spearman_values, marker='o', label= \"Spearman\")\n",
        "plt.plot(modification_rates, ktau_values, marker='o', label= \"Kendall Tau\")\n",
        "\n",
        "plt.xlabel(\"Modification Percentage\")\n",
        "plt.ylabel(\"Correlation\")\n",
        "plt.title(\"Correlation of Eigenvector Centrality (Original vs Modified)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p2zl2S5_UgLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read correlations from stored files G1, G2, ..\n",
        "\n",
        "pearson_values = []\n",
        "spearman_values = []\n",
        "ktau_values = []\n",
        "\n",
        "\n",
        "for j in range(8):\n",
        "\n",
        "  # Define the path to your JSON file\n",
        "  file_path = f'/content/drive/MyDrive/Colab_Notebooks/eigen/eigen_correlations_matrices_G{j+1}.json'\n",
        "\n",
        "  # Open and read the JSON file\n",
        "  with open(file_path, 'r') as json_file:\n",
        "      corr_dict = json.load(json_file)\n",
        "\n",
        "      if j== 0:\n",
        "        pearson_values.extend(corr_dict[\"pearson_values\"])\n",
        "        spearman_values.extend(corr_dict[\"spearman_values\"])\n",
        "        ktau_values.extend(corr_dict[\"ktau_values\"])\n",
        "      else:\n",
        "        pearson_values = np.vstack((pearson_values, corr_dict[\"pearson_values\"]))\n",
        "        spearman_values = np.vstack((spearman_values, corr_dict[\"spearman_values\"]))\n",
        "        ktau_values = np.vstack((ktau_values, corr_dict[\"ktau_values\"]))\n",
        "\n",
        "\n",
        "# Ready to be plotted (results from all matrices horray!)\n",
        "pearson_values = list(np.mean(pearson_values, axis=0))\n",
        "spearman_values = list(np.mean(spearman_values, axis=0))\n",
        "ktau_values = list(np.mean(ktau_values, axis=0))\n",
        "\n",
        "\n",
        "\n",
        "# Plot results\n",
        "modification_rates = [f\"{i}%\" for i in range(0,110,10)]\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "plt.plot(modification_rates, pearson_values, marker='o', label= \"Pearson\")\n",
        "plt.plot(modification_rates, spearman_values, marker='o', label= \"Spearman\")\n",
        "plt.plot(modification_rates, ktau_values, marker='o', label= \"Kendall Tau\")\n",
        "\n",
        "plt.xlabel(\"Modification Percentage\")\n",
        "plt.ylabel(\"Correlation\")\n",
        "plt.title(\"Correlation of Eigenvector Centrality (Original vs Modified)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fwVQsIliPe6T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}